theme: default # default || classic || dark
# organization: Pixel Genius Labs
# twitter: '@denkivvakame'
title: 'Decompose and Reorganize: Planning with  Primitives and Visuomotor Policies Learned from Demonstrations'
tabTitle: 'DR-LfD' # Short title for browser tab
# journal: "AAAA'24"
resources:
  paper: https://openreview.net/
  arxiv: https://arxiv.org
  code: https://github.com/denkiwakame/academic-project-template
  video: https://www.youtube.com/embed/onbnb_D1wC8?si=xJczUv716Lt5aO4l&amp;start=1150
#   demo: https://colab.research.google.com/
#   huggingface: https://huggingface.co/
# description: academic projectpage template that supports markdown and KaTeX

image: https://denkiwakame.github.io/academic-project-template/teaser.jpg
url: https://denkiwakame.github.io/academic-project-template
speakerdeck: # speakerdeck slide ID
authors:
  - name: Anonymous
    affiliation: [1]
    position: Researcher
    url: https://thispersondoesnotexist.com/
affiliations:
  - Anonymous

teaser: paper-figures/tro-teaser.png
abstract: |
  Imitation learning (IL), particularly when leveraging high-dimensional visual inputs for policy training, has proven intuitive and effective in complex bimanual manipulation tasks. Nonetheless, the generalization capability of visuomotor policies remains limited, especially when only limited amounts of demonstrations are available. 
  Furthermore, accumulated errors in visuomotor policies significantly hinder their ability to complete long-horizon tasks. To address these limitations, we propose *DR-LfD* (<u>D</u>ecomposed and <u>R</u>eorganized Skills <u>L</u>earned <u>f</u>rom <u>D</u>emonstrations), a framework that seamlessly integrates visuomotor policies into task and motion planning (TAMP). Adopting a scene-graph-like representation, DR-LfD partitions human demonstrations into symbolic subgoals with the help of a vision-language model (VLM). Continuous decision variables from the key scene graph are employed to train object-centric motion primitives, whose equivariant network structure enables reliable performance even when encountering out-of-distribution observations.
  With a handful of demonstrations, DR-LfD enables visuomotor policies to generalize across out-of-distribution initial conditions without data-hungry pre-training and per-object 6DoF pose estimation.
  By leveraging TAMP formulation, DR-LfD can achieve a combinatorial number of goals while the number of demonstrations is linear to skill types.
  In four real-world experiments featuring two distinct dual-arm manipulator systems, DR-LfD outperforms state-of-the-art generative IL methods, indicating wider applicability for more complex tasks.
body:
  - title: 'Peg-in-hole task (simulation, speed: 2X)'
    text: |
      ### *OOD* Setup
      The peg and the socket are placed on the right half and left half of the table, respectively, with  the position and orientation randomly initialized.

      <div class="uk-grid-small uk-child-width-1-3@s uk-child-width-1-6@m" uk-grid>
        <div>
          <img src="unreach_unsafe/ood1.gif">
        </div>
        <div>
          <img src="unreach_unsafe/ood2.gif">
        </div>
        <div>
          <img src="unreach_unsafe/ood3.gif">
        </div>
        <div>
          <img src="unreach_unsafe/ood4.gif">
        </div>
        <div>
          <img src="unreach_unsafe/ood5.gif">
        </div>
        <div>
          <img src="unreach_unsafe/ood6.gif">
        </div>
      </div>

      ### *Unreachable* Setup
      The peg and the socket are initialized on one side of the table, and the bimaual manipulation cannot be directly operated.

      <div class="uk-grid-small uk-child-width-1-3@s uk-child-width-1-6@m" uk-grid>
        <div>
          <img src="unreach_unsafe/reach1.gif">
        </div>
        <div>
          <img src="unreach_unsafe/reach2.gif">
        </div>
        <div>
          <img src="unreach_unsafe/reach3.gif">
        </div>
        <div>
          <img src="unreach_unsafe/reach4.gif">
        </div>
        <div>
          <img src="unreach_unsafe/reach5.gif">
        </div>
        <div>
          <img src="unreach_unsafe/reach6.gif">
        </div>
      </div>

      ### *Unsafe* Setup
      An unexpected obstacle obstructs the space required by the bimanual manipulation.

      <div class="uk-grid-small uk-child-width-1-3@s uk-child-width-1-6@m" uk-grid>
        <div>
          <img src="unreach_unsafe/safe1.gif">
        </div>
        <div>
          <img src="unreach_unsafe/safe2.gif">
        </div>
        <div>
          <img src="unreach_unsafe/safe3.gif">
        </div>
        <div>
          <img src="unreach_unsafe/safe4.gif">
        </div>
        <div>
          <img src="unreach_unsafe/safe5.gif">
        </div>
        <div>
          <img src="unreach_unsafe/safe6.gif">
        </div>
      </div>

  - title: 'Overcoming unseen, random setups (real-world, speed: 4X)'
    text: |
      Handing off an object from right to left
      <div class="uk-grid-small uk-child-width-1-2@s uk-child-width-1-4@m" uk-grid>
        <div>
          <img src="tape_leaky/tape1.gif">
        </div>
        <div>
          <img src="tape_leaky/tape2.gif">
        </div>
        <div>
          <img src="tape_leaky/tape3.gif">
        </div>
        <div>
          <img src="tape_leaky/tape4.gif">
        </div>
      </div>

      Grasp a screwdriver and pack it up
      <div class="uk-grid-small uk-child-width-1-2@s uk-child-width-1-4@m" uk-grid>
        <div>
          <img src="screw_leaky/screw1.gif">
        </div>
        <div>
          <img src="screw_leaky/screw2.gif">
        </div>
        <div>
          <img src="screw_leaky/screw3.gif">
        </div>
        <div>
          <img src="screw_leaky/screw4.gif">
        </div>
      </div>

      <div class="uk-grid-small uk-child-width-1-2@s uk-child-width-1-4@m" uk-grid>
        <div>
          <img src="franka_screw/screw1.gif">
        </div>
        <div>
          <img src="franka_screw/screw2.gif">
        </div>
        <div>
          <img src="franka_screw/screw3.gif">
        </div>
        <div>
          <img src="franka_screw/screw4.gif">
        </div>
      </div>

      <div class="uk-grid-small uk-child-width-1-1@s uk-child-width-1-2@m" uk-grid>
        <div>
          <img src="ppt-pics/throw_screw_web.gif">
        </div>
        <div>
          <h3>Randomization via Tossing</h3>
          <p>With a small amount of demonstrations, SViP can adapt to unseen object placements and accomplish gestures that the leader arm of the teleoperation system cannot reach.</p>
        </div>
      </div>

      <div class="uk-grid-small uk-child-width-1-1@s" uk-grid>
        <div class="uk-width-1-1@m">
          <img src="ppt-pics/3skills_web.gif">
        </div>
      </div>


      <div class="uk-grid-small uk-child-width-1-1@s" uk-grid>
        <div class="uk-width-1-1@m">
          <img src="ppt-pics/3tape_web.gif">
        </div>
      </div>

projects: # relevant projects
  - title: Relevant Project I
    description: abstract text
    img: https://getuikit.com/docs/images/light.jpg
    journal: "ABCD'23"
    url: https://denkiwakame.github.io/academic-project-template/
  - title: Relevant Project II
    description: abstract text
    img: 001.jpg
    journal: "EFGH'22"
    url: https://denkiwakame.github.io/academic-project-template/
  - title: Relevant Project III
    description: abstract text
    img: 002.jpg
    journal: "IJKL'22"
    url: https://denkiwakame.github.io/academic-project-template/
